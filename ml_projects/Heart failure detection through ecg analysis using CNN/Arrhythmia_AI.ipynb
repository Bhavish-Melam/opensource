{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Harsh-017/ECGGuard/blob/main/Arrhythmia_AI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "^C\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting kaggle\n",
            "  Downloading kaggle-1.6.17.tar.gz (82 kB)\n",
            "     ---------------------------------------- 0.0/82.7 kB ? eta -:--:--\n",
            "     ---- ----------------------------------- 10.2/82.7 kB ? eta -:--:--\n",
            "     ---- ----------------------------------- 10.2/82.7 kB ? eta -:--:--\n",
            "     -------------- ----------------------- 30.7/82.7 kB 186.2 kB/s eta 0:00:01\n",
            "     ---------------------------- --------- 61.4/82.7 kB 326.1 kB/s eta 0:00:01\n",
            "     -------------------------------------- 82.7/82.7 kB 385.4 kB/s eta 0:00:00\n",
            "  Installing build dependencies: started\n",
            "  Installing build dependencies: finished with status 'done'\n",
            "  Getting requirements to build wheel: started\n",
            "  Getting requirements to build wheel: finished with status 'done'\n",
            "  Preparing metadata (pyproject.toml): started\n",
            "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
            "Collecting kagglehub[pandas-datasets]\n",
            "  Downloading kagglehub-0.3.7-py3-none-any.whl.metadata (30 kB)\n",
            "Requirement already satisfied: six>=1.10 in c:\\users\\charan\\desktop\\ml_projects\\arrythmia_ai\\venv\\lib\\site-packages (from kaggle) (1.17.0)\n",
            "Collecting certifi>=2023.7.22 (from kaggle)\n",
            "  Downloading certifi-2025.1.31-py3-none-any.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: python-dateutil in c:\\users\\charan\\desktop\\ml_projects\\arrythmia_ai\\venv\\lib\\site-packages (from kaggle) (2.9.0.post0)\n",
            "Collecting requests (from kaggle)\n",
            "  Using cached requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting tqdm (from kaggle)\n",
            "  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
            "Collecting python-slugify (from kaggle)\n",
            "  Downloading python_slugify-8.0.4-py2.py3-none-any.whl.metadata (8.5 kB)\n",
            "Collecting urllib3 (from kaggle)\n",
            "  Downloading urllib3-2.3.0-py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting bleach (from kaggle)\n",
            "  Downloading bleach-6.2.0-py3-none-any.whl.metadata (30 kB)\n",
            "Collecting model-signing (from kagglehub[pandas-datasets])\n",
            "  Downloading model_signing-0.2.0-py3-none-any.whl.metadata (26 kB)\n",
            "Requirement already satisfied: packaging in c:\\users\\charan\\desktop\\ml_projects\\arrythmia_ai\\venv\\lib\\site-packages (from kagglehub[pandas-datasets]) (24.2)\n",
            "Collecting pandas (from kagglehub[pandas-datasets])\n",
            "  Using cached pandas-2.2.3-cp311-cp311-win_amd64.whl.metadata (19 kB)\n",
            "Collecting webencodings (from bleach->kaggle)\n",
            "  Using cached webencodings-0.5.1-py2.py3-none-any.whl.metadata (2.1 kB)\n",
            "Collecting cryptography (from model-signing->kagglehub[pandas-datasets])\n",
            "  Downloading cryptography-44.0.1-cp39-abi3-win_amd64.whl.metadata (5.7 kB)\n",
            "Collecting in-toto-attestation (from model-signing->kagglehub[pandas-datasets])\n",
            "  Downloading in_toto_attestation-0.9.3-py3-none-any.whl.metadata (2.6 kB)\n",
            "Collecting sigstore (from model-signing->kagglehub[pandas-datasets])\n",
            "  Downloading sigstore-3.6.1-py3-none-any.whl.metadata (15 kB)\n",
            "Requirement already satisfied: typing-extensions in c:\\users\\charan\\desktop\\ml_projects\\arrythmia_ai\\venv\\lib\\site-packages (from model-signing->kagglehub[pandas-datasets]) (4.12.2)\n",
            "Collecting numpy>=1.23.2 (from pandas->kagglehub[pandas-datasets])\n",
            "  Downloading numpy-2.2.2-cp311-cp311-win_amd64.whl.metadata (60 kB)\n",
            "     ---------------------------------------- 0.0/60.8 kB ? eta -:--:--\n",
            "     ---------------------------------------- 60.8/60.8 kB 1.6 MB/s eta 0:00:00\n",
            "Collecting pytz>=2020.1 (from pandas->kagglehub[pandas-datasets])\n",
            "  Downloading pytz-2025.1-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Collecting tzdata>=2022.7 (from pandas->kagglehub[pandas-datasets])\n",
            "  Downloading tzdata-2025.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting text-unidecode>=1.3 (from python-slugify->kaggle)\n",
            "  Using cached text_unidecode-1.3-py2.py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting charset-normalizer<4,>=2 (from requests->kaggle)\n",
            "  Downloading charset_normalizer-3.4.1-cp311-cp311-win_amd64.whl.metadata (36 kB)\n",
            "Collecting idna<4,>=2.5 (from requests->kaggle)\n",
            "  Using cached idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: colorama in c:\\users\\charan\\desktop\\ml_projects\\arrythmia_ai\\venv\\lib\\site-packages (from tqdm->kaggle) (0.4.6)\n",
            "Collecting cffi>=1.12 (from cryptography->model-signing->kagglehub[pandas-datasets])\n",
            "  Downloading cffi-1.17.1-cp311-cp311-win_amd64.whl.metadata (1.6 kB)\n",
            "Collecting protobuf (from in-toto-attestation->model-signing->kagglehub[pandas-datasets])\n",
            "  Downloading protobuf-5.29.3-cp310-abi3-win_amd64.whl.metadata (592 bytes)\n",
            "Collecting id>=1.1.0 (from sigstore->model-signing->kagglehub[pandas-datasets])\n",
            "  Downloading id-1.5.0-py3-none-any.whl.metadata (5.2 kB)\n",
            "Collecting pyasn1~=0.6 (from sigstore->model-signing->kagglehub[pandas-datasets])\n",
            "  Downloading pyasn1-0.6.1-py3-none-any.whl.metadata (8.4 kB)\n",
            "Collecting pydantic<3,>=2 (from sigstore->model-signing->kagglehub[pandas-datasets])\n",
            "  Downloading pydantic-2.10.6-py3-none-any.whl.metadata (30 kB)\n",
            "Collecting pyjwt>=2.1 (from sigstore->model-signing->kagglehub[pandas-datasets])\n",
            "  Downloading PyJWT-2.10.1-py3-none-any.whl.metadata (4.0 kB)\n",
            "Collecting pyOpenSSL>=23.0.0 (from sigstore->model-signing->kagglehub[pandas-datasets])\n",
            "  Downloading pyOpenSSL-25.0.0-py3-none-any.whl.metadata (16 kB)\n",
            "Collecting rich~=13.0 (from sigstore->model-signing->kagglehub[pandas-datasets])\n",
            "  Downloading rich-13.9.4-py3-none-any.whl.metadata (18 kB)\n",
            "Collecting rfc8785~=0.1.2 (from sigstore->model-signing->kagglehub[pandas-datasets])\n",
            "  Downloading rfc8785-0.1.4-py3-none-any.whl.metadata (3.4 kB)\n",
            "Collecting rfc3161-client~=0.1.2 (from sigstore->model-signing->kagglehub[pandas-datasets])\n",
            "  Downloading rfc3161_client-0.1.2-cp39-abi3-win_amd64.whl.metadata (3.0 kB)\n",
            "Collecting sigstore-protobuf-specs==0.3.2 (from sigstore->model-signing->kagglehub[pandas-datasets])\n",
            "  Downloading sigstore_protobuf_specs-0.3.2-py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting sigstore-rekor-types==0.0.18 (from sigstore->model-signing->kagglehub[pandas-datasets])\n",
            "  Downloading sigstore_rekor_types-0.0.18-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting tuf~=5.0 (from sigstore->model-signing->kagglehub[pandas-datasets])\n",
            "  Downloading tuf-5.1.0-py3-none-any.whl.metadata (7.9 kB)\n",
            "Requirement already satisfied: platformdirs~=4.2 in c:\\users\\charan\\desktop\\ml_projects\\arrythmia_ai\\venv\\lib\\site-packages (from sigstore->model-signing->kagglehub[pandas-datasets]) (4.3.6)\n",
            "Collecting betterproto==2.0.0b6 (from sigstore-protobuf-specs==0.3.2->sigstore->model-signing->kagglehub[pandas-datasets])\n",
            "  Downloading betterproto-2.0.0b6-py3-none-any.whl.metadata (17 kB)\n",
            "Collecting grpclib<0.5.0,>=0.4.1 (from betterproto==2.0.0b6->sigstore-protobuf-specs==0.3.2->sigstore->model-signing->kagglehub[pandas-datasets])\n",
            "  Downloading grpclib-0.4.7.tar.gz (61 kB)\n",
            "     ---------------------------------------- 0.0/61.3 kB ? eta -:--:--\n",
            "     ---------------------------------------- 61.3/61.3 kB 1.6 MB/s eta 0:00:00\n",
            "  Installing build dependencies: started\n",
            "  Installing build dependencies: finished with status 'done'\n",
            "  Getting requirements to build wheel: started\n",
            "  Getting requirements to build wheel: finished with status 'done'\n",
            "  Preparing metadata (pyproject.toml): started\n",
            "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
            "Collecting pycparser (from cffi>=1.12->cryptography->model-signing->kagglehub[pandas-datasets])\n",
            "  Downloading pycparser-2.22-py3-none-any.whl.metadata (943 bytes)\n",
            "Collecting annotated-types>=0.6.0 (from pydantic<3,>=2->sigstore->model-signing->kagglehub[pandas-datasets])\n",
            "  Using cached annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
            "Collecting pydantic-core==2.27.2 (from pydantic<3,>=2->sigstore->model-signing->kagglehub[pandas-datasets])\n",
            "  Using cached pydantic_core-2.27.2-cp311-cp311-win_amd64.whl.metadata (6.7 kB)\n",
            "Collecting markdown-it-py>=2.2.0 (from rich~=13.0->sigstore->model-signing->kagglehub[pandas-datasets])\n",
            "  Downloading markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\charan\\desktop\\ml_projects\\arrythmia_ai\\venv\\lib\\site-packages (from rich~=13.0->sigstore->model-signing->kagglehub[pandas-datasets]) (2.19.1)\n",
            "Collecting securesystemslib~=1.0 (from tuf~=5.0->sigstore->model-signing->kagglehub[pandas-datasets])\n",
            "  Downloading securesystemslib-1.2.0-py3-none-any.whl.metadata (4.8 kB)\n",
            "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich~=13.0->sigstore->model-signing->kagglehub[pandas-datasets])\n",
            "  Downloading mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
            "Collecting email-validator>=2.0.0 (from pydantic[email]<3,>=2->sigstore-rekor-types==0.0.18->sigstore->model-signing->kagglehub[pandas-datasets])\n",
            "  Using cached email_validator-2.2.0-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting dnspython>=2.0.0 (from email-validator>=2.0.0->pydantic[email]<3,>=2->sigstore-rekor-types==0.0.18->sigstore->model-signing->kagglehub[pandas-datasets])\n",
            "  Using cached dnspython-2.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Collecting h2<5,>=3.1.0 (from grpclib<0.5.0,>=0.4.1->betterproto==2.0.0b6->sigstore-protobuf-specs==0.3.2->sigstore->model-signing->kagglehub[pandas-datasets])\n",
            "  Downloading h2-4.2.0-py3-none-any.whl.metadata (5.1 kB)\n",
            "Collecting multidict (from grpclib<0.5.0,>=0.4.1->betterproto==2.0.0b6->sigstore-protobuf-specs==0.3.2->sigstore->model-signing->kagglehub[pandas-datasets])\n",
            "  Using cached multidict-6.1.0-cp311-cp311-win_amd64.whl.metadata (5.1 kB)\n",
            "Collecting hyperframe<7,>=6.1 (from h2<5,>=3.1.0->grpclib<0.5.0,>=0.4.1->betterproto==2.0.0b6->sigstore-protobuf-specs==0.3.2->sigstore->model-signing->kagglehub[pandas-datasets])\n",
            "  Downloading hyperframe-6.1.0-py3-none-any.whl.metadata (4.3 kB)\n",
            "Collecting hpack<5,>=4.1 (from h2<5,>=3.1.0->grpclib<0.5.0,>=0.4.1->betterproto==2.0.0b6->sigstore-protobuf-specs==0.3.2->sigstore->model-signing->kagglehub[pandas-datasets])\n",
            "  Downloading hpack-4.1.0-py3-none-any.whl.metadata (4.6 kB)\n",
            "Downloading certifi-2025.1.31-py3-none-any.whl (166 kB)\n",
            "   ---------------------------------------- 0.0/166.4 kB ? eta -:--:--\n",
            "   ---------------------------------- ----- 143.4/166.4 kB 2.8 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 166.4/166.4 kB 2.0 MB/s eta 0:00:00\n",
            "Downloading bleach-6.2.0-py3-none-any.whl (163 kB)\n",
            "   ---------------------------------------- 0.0/163.4 kB ? eta -:--:--\n",
            "   ---------------------------------------- 163.4/163.4 kB 4.8 MB/s eta 0:00:00\n",
            "Downloading kagglehub-0.3.7-py3-none-any.whl (54 kB)\n",
            "   ---------------------------------------- 0.0/54.5 kB ? eta -:--:--\n",
            "   ---------------------------------------- 54.5/54.5 kB 3.0 MB/s eta 0:00:00\n",
            "Downloading model_signing-0.2.0-py3-none-any.whl (63 kB)\n",
            "   ---------------------------------------- 0.0/63.8 kB ? eta -:--:--\n",
            "   ---------------------------------------- 63.8/63.8 kB 3.4 MB/s eta 0:00:00\n",
            "Using cached pandas-2.2.3-cp311-cp311-win_amd64.whl (11.6 MB)\n",
            "Downloading python_slugify-8.0.4-py2.py3-none-any.whl (10 kB)\n",
            "Using cached requests-2.32.3-py3-none-any.whl (64 kB)\n",
            "Downloading urllib3-2.3.0-py3-none-any.whl (128 kB)\n",
            "   ---------------------------------------- 0.0/128.4 kB ? eta -:--:--\n",
            "   ---------------------------------------- 128.4/128.4 kB 7.9 MB/s eta 0:00:00\n",
            "Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
            "Downloading charset_normalizer-3.4.1-cp311-cp311-win_amd64.whl (102 kB)\n",
            "   ---------------------------------------- 0.0/102.4 kB ? eta -:--:--\n",
            "   ---------------------------------------- 102.4/102.4 kB 5.8 MB/s eta 0:00:00\n",
            "Using cached idna-3.10-py3-none-any.whl (70 kB)\n",
            "Downloading numpy-2.2.2-cp311-cp311-win_amd64.whl (12.9 MB)\n",
            "   ---------------------------------------- 0.0/12.9 MB ? eta -:--:--\n",
            "    --------------------------------------- 0.3/12.9 MB 8.3 MB/s eta 0:00:02\n",
            "   -- ------------------------------------- 0.8/12.9 MB 9.8 MB/s eta 0:00:02\n",
            "   ---- ----------------------------------- 1.5/12.9 MB 11.8 MB/s eta 0:00:01\n",
            "   ------ --------------------------------- 2.2/12.9 MB 12.5 MB/s eta 0:00:01\n",
            "   ---------- ----------------------------- 3.5/12.9 MB 15.8 MB/s eta 0:00:01\n",
            "   ---------- ----------------------------- 3.5/12.9 MB 15.8 MB/s eta 0:00:01\n",
            "   ---------- ----------------------------- 3.5/12.9 MB 12.5 MB/s eta 0:00:01\n",
            "   ------------ --------------------------- 4.2/12.9 MB 11.5 MB/s eta 0:00:01\n",
            "   -------------- ------------------------- 4.8/12.9 MB 11.7 MB/s eta 0:00:01\n",
            "   -------------- ------------------------- 4.8/12.9 MB 11.7 MB/s eta 0:00:01\n",
            "   --------------- ------------------------ 5.2/12.9 MB 11.0 MB/s eta 0:00:01\n",
            "   ---------------- ----------------------- 5.4/12.9 MB 10.1 MB/s eta 0:00:01\n",
            "   ----------------- ---------------------- 5.5/12.9 MB 9.3 MB/s eta 0:00:01\n",
            "   ----------------- ---------------------- 5.8/12.9 MB 9.4 MB/s eta 0:00:01\n",
            "   ----------------- ---------------------- 5.8/12.9 MB 9.4 MB/s eta 0:00:01\n",
            "   ------------------ --------------------- 6.1/12.9 MB 8.2 MB/s eta 0:00:01\n",
            "   ------------------- -------------------- 6.2/12.9 MB 7.9 MB/s eta 0:00:01\n",
            "   ------------------- -------------------- 6.2/12.9 MB 7.5 MB/s eta 0:00:01\n",
            "   ------------------- -------------------- 6.3/12.9 MB 7.2 MB/s eta 0:00:01\n",
            "   ------------------- -------------------- 6.4/12.9 MB 7.0 MB/s eta 0:00:01\n",
            "   -------------------- ------------------- 6.5/12.9 MB 6.8 MB/s eta 0:00:01\n",
            "   --------------------- ------------------ 6.8/12.9 MB 6.8 MB/s eta 0:00:01\n",
            "   --------------------- ------------------ 7.0/12.9 MB 6.5 MB/s eta 0:00:01\n",
            "   ------------------------ --------------- 7.8/12.9 MB 7.0 MB/s eta 0:00:01\n",
            "   ------------------------ --------------- 7.9/12.9 MB 6.9 MB/s eta 0:00:01\n",
            "   ------------------------ --------------- 8.0/12.9 MB 6.7 MB/s eta 0:00:01\n",
            "   -------------------------- ------------- 8.6/12.9 MB 6.8 MB/s eta 0:00:01\n",
            "   -------------------------- ------------- 8.6/12.9 MB 6.8 MB/s eta 0:00:01\n",
            "   --------------------------- ------------ 8.9/12.9 MB 6.7 MB/s eta 0:00:01\n",
            "   ---------------------------- ----------- 9.1/12.9 MB 6.5 MB/s eta 0:00:01\n",
            "   ---------------------------- ----------- 9.2/12.9 MB 6.4 MB/s eta 0:00:01\n",
            "   ---------------------------- ----------- 9.3/12.9 MB 6.3 MB/s eta 0:00:01\n",
            "   ----------------------------- ---------- 9.4/12.9 MB 6.1 MB/s eta 0:00:01\n",
            "   ----------------------------- ---------- 9.5/12.9 MB 6.0 MB/s eta 0:00:01\n",
            "   ----------------------------- ---------- 9.6/12.9 MB 6.0 MB/s eta 0:00:01\n",
            "   ------------------------------ --------- 9.7/12.9 MB 5.9 MB/s eta 0:00:01\n",
            "   ------------------------------ --------- 9.8/12.9 MB 5.7 MB/s eta 0:00:01\n",
            "   ------------------------------ --------- 9.9/12.9 MB 5.6 MB/s eta 0:00:01\n",
            "   ------------------------------- -------- 10.0/12.9 MB 5.5 MB/s eta 0:00:01\n",
            "   ------------------------------- -------- 10.1/12.9 MB 5.4 MB/s eta 0:00:01\n",
            "   ------------------------------- -------- 10.2/12.9 MB 5.3 MB/s eta 0:00:01\n",
            "   ------------------------------- -------- 10.3/12.9 MB 5.2 MB/s eta 0:00:01\n",
            "   -------------------------------- ------- 10.4/12.9 MB 5.1 MB/s eta 0:00:01\n",
            "   -------------------------------- ------- 10.4/12.9 MB 5.0 MB/s eta 0:00:01\n",
            "   -------------------------------- ------- 10.5/12.9 MB 5.0 MB/s eta 0:00:01\n",
            "   -------------------------------- ------- 10.6/12.9 MB 4.9 MB/s eta 0:00:01\n",
            "   --------------------------------- ------ 10.7/12.9 MB 4.8 MB/s eta 0:00:01\n",
            "   --------------------------------- ------ 10.8/12.9 MB 4.7 MB/s eta 0:00:01\n",
            "   --------------------------------- ------ 10.9/12.9 MB 4.6 MB/s eta 0:00:01\n",
            "   --------------------------------- ------ 11.0/12.9 MB 4.5 MB/s eta 0:00:01\n",
            "   ---------------------------------- ----- 11.1/12.9 MB 4.5 MB/s eta 0:00:01\n",
            "   ---------------------------------- ----- 11.2/12.9 MB 4.4 MB/s eta 0:00:01\n",
            "   ---------------------------------- ----- 11.3/12.9 MB 4.3 MB/s eta 0:00:01\n",
            "   ----------------------------------- ---- 11.4/12.9 MB 4.3 MB/s eta 0:00:01\n",
            "   ----------------------------------- ---- 11.4/12.9 MB 4.2 MB/s eta 0:00:01\n",
            "   ----------------------------------- ---- 11.5/12.9 MB 4.1 MB/s eta 0:00:01\n",
            "   ------------------------------------ --- 11.6/12.9 MB 4.0 MB/s eta 0:00:01\n",
            "   ------------------------------------ --- 11.7/12.9 MB 4.0 MB/s eta 0:00:01\n",
            "   ------------------------------------ --- 11.8/12.9 MB 3.9 MB/s eta 0:00:01\n",
            "   ------------------------------------ --- 11.9/12.9 MB 3.9 MB/s eta 0:00:01\n",
            "   ------------------------------------- -- 12.0/12.9 MB 3.8 MB/s eta 0:00:01\n",
            "   ------------------------------------- -- 12.1/12.9 MB 3.7 MB/s eta 0:00:01\n",
            "   ------------------------------------- -- 12.2/12.9 MB 3.7 MB/s eta 0:00:01\n",
            "   -------------------------------------- - 12.3/12.9 MB 3.6 MB/s eta 0:00:01\n",
            "   -------------------------------------- - 12.4/12.9 MB 3.6 MB/s eta 0:00:01\n",
            "   -------------------------------------- - 12.5/12.9 MB 3.5 MB/s eta 0:00:01\n",
            "   -------------------------------------- - 12.6/12.9 MB 3.5 MB/s eta 0:00:01\n",
            "   ---------------------------------------  12.7/12.9 MB 3.4 MB/s eta 0:00:01\n",
            "   ---------------------------------------  12.8/12.9 MB 3.4 MB/s eta 0:00:01\n",
            "   ---------------------------------------  12.9/12.9 MB 3.3 MB/s eta 0:00:01\n",
            "   ---------------------------------------  12.9/12.9 MB 3.3 MB/s eta 0:00:01\n",
            "   ---------------------------------------  12.9/12.9 MB 3.3 MB/s eta 0:00:01\n",
            "   ---------------------------------------  12.9/12.9 MB 3.3 MB/s eta 0:00:01\n",
            "   ---------------------------------------  12.9/12.9 MB 3.3 MB/s eta 0:00:01\n",
            "   ---------------------------------------  12.9/12.9 MB 3.3 MB/s eta 0:00:01\n",
            "   ---------------------------------------  12.9/12.9 MB 3.3 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 12.9/12.9 MB 3.0 MB/s eta 0:00:00\n",
            "Downloading pytz-2025.1-py2.py3-none-any.whl (507 kB)\n",
            "   ---------------------------------------- 0.0/507.9 kB ? eta -:--:--\n",
            "   ------- -------------------------------- 92.2/507.9 kB 5.1 MB/s eta 0:00:01\n",
            "   ---------------- ----------------------- 204.8/507.9 kB 2.5 MB/s eta 0:00:01\n",
            "   ------------------------ --------------- 307.2/507.9 kB 2.4 MB/s eta 0:00:01\n",
            "   -------------------------------- ------- 409.6/507.9 kB 2.3 MB/s eta 0:00:01\n",
            "   ---------------------------------------  501.8/507.9 kB 2.2 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 507.9/507.9 kB 2.0 MB/s eta 0:00:00\n",
            "Using cached text_unidecode-1.3-py2.py3-none-any.whl (78 kB)\n",
            "Downloading tzdata-2025.1-py2.py3-none-any.whl (346 kB)\n",
            "   ---------------------------------------- 0.0/346.8 kB ? eta -:--:--\n",
            "   -------------- ------------------------- 122.9/346.8 kB 2.4 MB/s eta 0:00:01\n",
            "   ------------------------- -------------- 225.3/346.8 kB 2.3 MB/s eta 0:00:01\n",
            "   -------------------------------------- - 337.9/346.8 kB 2.3 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 346.8/346.8 kB 2.0 MB/s eta 0:00:00\n",
            "Downloading cryptography-44.0.1-cp39-abi3-win_amd64.whl (3.2 MB)\n",
            "   ---------------------------------------- 0.0/3.2 MB ? eta -:--:--\n",
            "   - -------------------------------------- 0.1/3.2 MB 2.4 MB/s eta 0:00:02\n",
            "   -- ------------------------------------- 0.2/3.2 MB 2.8 MB/s eta 0:00:02\n",
            "   ---- ----------------------------------- 0.3/3.2 MB 2.3 MB/s eta 0:00:02\n",
            "   ----- ---------------------------------- 0.4/3.2 MB 2.3 MB/s eta 0:00:02\n",
            "   ------ --------------------------------- 0.6/3.2 MB 2.3 MB/s eta 0:00:02\n",
            "   -------- ------------------------------- 0.7/3.2 MB 2.3 MB/s eta 0:00:02\n",
            "   --------- ------------------------------ 0.8/3.2 MB 2.4 MB/s eta 0:00:02\n",
            "   ---------- ----------------------------- 0.9/3.2 MB 2.3 MB/s eta 0:00:02\n",
            "   ------------ --------------------------- 1.0/3.2 MB 2.4 MB/s eta 0:00:01\n",
            "   ------------- -------------------------- 1.1/3.2 MB 2.3 MB/s eta 0:00:01\n",
            "   --------------- ------------------------ 1.2/3.2 MB 2.3 MB/s eta 0:00:01\n",
            "   ---------------- ----------------------- 1.3/3.2 MB 2.3 MB/s eta 0:00:01\n",
            "   ----------------- ---------------------- 1.4/3.2 MB 2.4 MB/s eta 0:00:01\n",
            "   ------------------- -------------------- 1.6/3.2 MB 2.4 MB/s eta 0:00:01\n",
            "   -------------------- ------------------- 1.6/3.2 MB 2.4 MB/s eta 0:00:01\n",
            "   --------------------- ------------------ 1.8/3.2 MB 2.4 MB/s eta 0:00:01\n",
            "   ----------------------- ---------------- 1.9/3.2 MB 2.4 MB/s eta 0:00:01\n",
            "   ------------------------ --------------- 2.0/3.2 MB 2.3 MB/s eta 0:00:01\n",
            "   -------------------------- ------------- 2.1/3.2 MB 2.4 MB/s eta 0:00:01\n",
            "   --------------------------- ------------ 2.2/3.2 MB 2.3 MB/s eta 0:00:01\n",
            "   ----------------------------- ---------- 2.3/3.2 MB 2.4 MB/s eta 0:00:01\n",
            "   ------------------------------ --------- 2.5/3.2 MB 2.4 MB/s eta 0:00:01\n",
            "   -------------------------------- ------- 2.6/3.2 MB 2.4 MB/s eta 0:00:01\n",
            "   --------------------------------- ------ 2.7/3.2 MB 2.4 MB/s eta 0:00:01\n",
            "   ---------------------------------- ----- 2.8/3.2 MB 2.4 MB/s eta 0:00:01\n",
            "   ------------------------------------ --- 2.9/3.2 MB 2.4 MB/s eta 0:00:01\n",
            "   ------------------------------------- -- 3.0/3.2 MB 2.4 MB/s eta 0:00:01\n",
            "   ---------------------------------------  3.2/3.2 MB 2.4 MB/s eta 0:00:01\n",
            "   ---------------------------------------  3.2/3.2 MB 2.4 MB/s eta 0:00:01\n",
            "   ---------------------------------------  3.2/3.2 MB 2.4 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 3.2/3.2 MB 2.3 MB/s eta 0:00:00\n",
            "Downloading in_toto_attestation-0.9.3-py3-none-any.whl (13 kB)\n",
            "Downloading sigstore-3.6.1-py3-none-any.whl (99 kB)\n",
            "   ---------------------------------------- 0.0/99.2 kB ? eta -:--:--\n",
            "   ------------------------------------- -- 92.2/99.2 kB 5.1 MB/s eta 0:00:01\n",
            "   ------------------------------------- -- 92.2/99.2 kB 5.1 MB/s eta 0:00:01\n",
            "   ------------------------------------- -- 92.2/99.2 kB 5.1 MB/s eta 0:00:01\n",
            "   ------------------------------------- -- 92.2/99.2 kB 5.1 MB/s eta 0:00:01\n",
            "   ------------------------------------- -- 92.2/99.2 kB 5.1 MB/s eta 0:00:01\n",
            "   ------------------------------------- -- 92.2/99.2 kB 5.1 MB/s eta 0:00:01\n",
            "   ------------------------------------- -- 92.2/99.2 kB 5.1 MB/s eta 0:00:01\n",
            "   ------------------------------------- -- 92.2/99.2 kB 5.1 MB/s eta 0:00:01\n",
            "   ------------------------------------- -- 92.2/99.2 kB 5.1 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 99.2/99.2 kB 210.7 kB/s eta 0:00:00\n",
            "Downloading sigstore_protobuf_specs-0.3.2-py3-none-any.whl (24 kB)\n",
            "Downloading sigstore_rekor_types-0.0.18-py3-none-any.whl (20 kB)\n",
            "Downloading betterproto-2.0.0b6-py3-none-any.whl (64 kB)\n",
            "   ---------------------------------------- 0.0/64.3 kB ? eta -:--:--\n",
            "   -------------------------------------- - 61.4/64.3 kB ? eta -:--:--\n",
            "   -------------------------------------- - 61.4/64.3 kB ? eta -:--:--\n",
            "   -------------------------------------- - 61.4/64.3 kB ? eta -:--:--\n",
            "   -------------------------------------- - 61.4/64.3 kB ? eta -:--:--\n",
            "   -------------------------------------- - 61.4/64.3 kB ? eta -:--:--\n",
            "   -------------------------------------- - 61.4/64.3 kB ? eta -:--:--\n",
            "   ---------------------------------------- 64.3/64.3 kB 181.9 kB/s eta 0:00:00\n",
            "Using cached webencodings-0.5.1-py2.py3-none-any.whl (11 kB)\n",
            "Downloading cffi-1.17.1-cp311-cp311-win_amd64.whl (181 kB)\n",
            "   ---------------------------------------- 0.0/181.4 kB ? eta -:--:--\n",
            "   --------------------------- ------------ 122.9/181.4 kB 2.4 MB/s eta 0:00:01\n",
            "   -------------------------------------- - 174.1/181.4 kB 2.6 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 181.4/181.4 kB 1.8 MB/s eta 0:00:00\n",
            "Downloading id-1.5.0-py3-none-any.whl (13 kB)\n",
            "Downloading pyasn1-0.6.1-py3-none-any.whl (83 kB)\n",
            "   ---------------------------------------- 0.0/83.1 kB ? eta -:--:--\n",
            "   ---------------------------------------  81.9/83.1 kB 4.5 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 83.1/83.1 kB 1.6 MB/s eta 0:00:00\n",
            "Downloading pydantic-2.10.6-py3-none-any.whl (431 kB)\n",
            "   ---------------------------------------- 0.0/431.7 kB ? eta -:--:--\n",
            "   --------- ------------------------------ 102.4/431.7 kB 2.9 MB/s eta 0:00:01\n",
            "   --------------------- ------------------ 235.5/431.7 kB 2.9 MB/s eta 0:00:01\n",
            "   -------------------------------- ------- 348.2/431.7 kB 2.7 MB/s eta 0:00:01\n",
            "   ---------------------------------------  430.1/431.7 kB 2.7 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 431.7/431.7 kB 2.1 MB/s eta 0:00:00\n",
            "Using cached pydantic_core-2.27.2-cp311-cp311-win_amd64.whl (2.0 MB)\n",
            "Downloading PyJWT-2.10.1-py3-none-any.whl (22 kB)\n",
            "Downloading pyOpenSSL-25.0.0-py3-none-any.whl (56 kB)\n",
            "   ---------------------------------------- 0.0/56.5 kB ? eta -:--:--\n",
            "   ---------------------------------------- 56.5/56.5 kB 1.5 MB/s eta 0:00:00\n",
            "Downloading rfc3161_client-0.1.2-cp39-abi3-win_amd64.whl (2.2 MB)\n",
            "   ---------------------------------------- 0.0/2.2 MB ? eta -:--:--\n",
            "   -- ------------------------------------- 0.1/2.2 MB 3.6 MB/s eta 0:00:01\n",
            "   ---- ----------------------------------- 0.2/2.2 MB 3.0 MB/s eta 0:00:01\n",
            "   ------ --------------------------------- 0.4/2.2 MB 2.9 MB/s eta 0:00:01\n",
            "   --------- ------------------------------ 0.5/2.2 MB 2.8 MB/s eta 0:00:01\n",
            "   ----------- ---------------------------- 0.6/2.2 MB 2.8 MB/s eta 0:00:01\n",
            "   ------------- -------------------------- 0.7/2.2 MB 2.7 MB/s eta 0:00:01\n",
            "   ---------------- ----------------------- 0.9/2.2 MB 2.7 MB/s eta 0:00:01\n",
            "   ------------------ --------------------- 1.0/2.2 MB 2.7 MB/s eta 0:00:01\n",
            "   -------------------- ------------------- 1.1/2.2 MB 2.7 MB/s eta 0:00:01\n",
            "   ---------------------- ----------------- 1.2/2.2 MB 2.7 MB/s eta 0:00:01\n",
            "   ------------------------- -------------- 1.4/2.2 MB 2.7 MB/s eta 0:00:01\n",
            "   --------------------------- ------------ 1.5/2.2 MB 2.7 MB/s eta 0:00:01\n",
            "   ----------------------------- ---------- 1.6/2.2 MB 2.7 MB/s eta 0:00:01\n",
            "   -------------------------------- ------- 1.8/2.2 MB 2.7 MB/s eta 0:00:01\n",
            "   ---------------------------------- ----- 1.9/2.2 MB 2.7 MB/s eta 0:00:01\n",
            "   ------------------------------------- -- 2.0/2.2 MB 2.7 MB/s eta 0:00:01\n",
            "   ---------------------------------------  2.1/2.2 MB 2.7 MB/s eta 0:00:01\n",
            "   ---------------------------------------  2.2/2.2 MB 2.7 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 2.2/2.2 MB 2.5 MB/s eta 0:00:00\n",
            "Downloading rfc8785-0.1.4-py3-none-any.whl (9.2 kB)\n",
            "Downloading rich-13.9.4-py3-none-any.whl (242 kB)\n",
            "   ---------------------------------------- 0.0/242.4 kB ? eta -:--:--\n",
            "   -------------------- ------------------- 122.9/242.4 kB 3.5 MB/s eta 0:00:01\n",
            "   -------------------------------------- - 235.5/242.4 kB 2.9 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 242.4/242.4 kB 2.5 MB/s eta 0:00:00\n",
            "Downloading tuf-5.1.0-py3-none-any.whl (50 kB)\n",
            "   ---------------------------------------- 0.0/50.8 kB ? eta -:--:--\n",
            "   ---------------------------------------- 50.8/50.8 kB 2.5 MB/s eta 0:00:00\n",
            "Downloading protobuf-5.29.3-cp310-abi3-win_amd64.whl (434 kB)\n",
            "   ---------------------------------------- 0.0/434.5 kB ? eta -:--:--\n",
            "   -------------- ------------------------- 153.6/434.5 kB 3.1 MB/s eta 0:00:01\n",
            "   ---------------------------- ----------- 307.2/434.5 kB 3.2 MB/s eta 0:00:01\n",
            "   ---------------------------------------  430.1/434.5 kB 3.0 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 434.5/434.5 kB 2.5 MB/s eta 0:00:00\n",
            "Using cached annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
            "Downloading markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
            "   ---------------------------------------- 0.0/87.5 kB ? eta -:--:--\n",
            "   ------------------------------------- -- 81.9/87.5 kB ? eta -:--:--\n",
            "   ---------------------------------------- 87.5/87.5 kB 1.6 MB/s eta 0:00:00\n",
            "Downloading securesystemslib-1.2.0-py3-none-any.whl (870 kB)\n",
            "   ---------------------------------------- 0.0/870.8 kB ? eta -:--:--\n",
            "   ------ --------------------------------- 143.4/870.8 kB 4.3 MB/s eta 0:00:01\n",
            "   ------------- -------------------------- 286.7/870.8 kB 3.5 MB/s eta 0:00:01\n",
            "   ------------------- -------------------- 419.8/870.8 kB 3.3 MB/s eta 0:00:01\n",
            "   ------------------------- -------------- 553.0/870.8 kB 3.2 MB/s eta 0:00:01\n",
            "   ------------------------------- -------- 686.1/870.8 kB 3.1 MB/s eta 0:00:01\n",
            "   ------------------------------------- -- 819.2/870.8 kB 3.0 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 870.8/870.8 kB 2.7 MB/s eta 0:00:00\n",
            "Downloading pycparser-2.22-py3-none-any.whl (117 kB)\n",
            "   ---------------------------------------- 0.0/117.6 kB ? eta -:--:--\n",
            "   -------------------------------------- - 112.6/117.6 kB 3.3 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 117.6/117.6 kB 1.7 MB/s eta 0:00:00\n",
            "Using cached email_validator-2.2.0-py3-none-any.whl (33 kB)\n",
            "Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
            "Using cached dnspython-2.7.0-py3-none-any.whl (313 kB)\n",
            "Downloading h2-4.2.0-py3-none-any.whl (60 kB)\n",
            "   ---------------------------------------- 0.0/61.0 kB ? eta -:--:--\n",
            "   ---------------------------------------- 61.0/61.0 kB 1.6 MB/s eta 0:00:00\n",
            "Using cached multidict-6.1.0-cp311-cp311-win_amd64.whl (28 kB)\n",
            "Downloading hpack-4.1.0-py3-none-any.whl (34 kB)\n",
            "Downloading hyperframe-6.1.0-py3-none-any.whl (13 kB)\n",
            "Building wheels for collected packages: kaggle, grpclib\n",
            "  Building wheel for kaggle (pyproject.toml): started\n",
            "  Building wheel for kaggle (pyproject.toml): finished with status 'done'\n",
            "  Created wheel for kaggle: filename=kaggle-1.6.17-py3-none-any.whl size=105854 sha256=fc32ee90af77de04d953cf86e999f906d90239f994cd659f0bb1efcd8e35d3af\n",
            "  Stored in directory: c:\\users\\charan\\appdata\\local\\pip\\cache\\wheels\\ff\\55\\fb\\b27a466be754d2a06ffe0e37b248d844f090a63b51becea85d\n",
            "  Building wheel for grpclib (pyproject.toml): started\n",
            "  Building wheel for grpclib (pyproject.toml): finished with status 'done'\n",
            "  Created wheel for grpclib: filename=grpclib-0.4.7-py3-none-any.whl size=76255 sha256=cd81dae3abed5655a09820d887c90619dffb368778f2ba685352657d74dec0f4\n",
            "  Stored in directory: c:\\users\\charan\\appdata\\local\\pip\\cache\\wheels\\1a\\6e\\f8\\47a179a8cf84417e94206ee7bdee3cc4219a011e6ca1973eb0\n",
            "Successfully built kaggle grpclib\n",
            "Installing collected packages: webencodings, text-unidecode, pytz, urllib3, tzdata, tqdm, securesystemslib, rfc8785, python-slugify, pyjwt, pydantic-core, pycparser, pyasn1, protobuf, numpy, multidict, mdurl, idna, hyperframe, hpack, dnspython, charset-normalizer, certifi, bleach, annotated-types, requests, pydantic, pandas, markdown-it-py, in-toto-attestation, h2, email-validator, cffi, tuf, rich, kaggle, id, grpclib, cryptography, sigstore-rekor-types, rfc3161-client, pyOpenSSL, betterproto, sigstore-protobuf-specs, sigstore, model-signing, kagglehub\n",
            "Successfully installed annotated-types-0.7.0 betterproto-2.0.0b6 bleach-6.2.0 certifi-2025.1.31 cffi-1.17.1 charset-normalizer-3.4.1 cryptography-44.0.1 dnspython-2.7.0 email-validator-2.2.0 grpclib-0.4.7 h2-4.2.0 hpack-4.1.0 hyperframe-6.1.0 id-1.5.0 idna-3.10 in-toto-attestation-0.9.3 kaggle-1.6.17 kagglehub-0.3.7 markdown-it-py-3.0.0 mdurl-0.1.2 model-signing-0.2.0 multidict-6.1.0 numpy-2.2.2 pandas-2.2.3 protobuf-5.29.3 pyOpenSSL-25.0.0 pyasn1-0.6.1 pycparser-2.22 pydantic-2.10.6 pydantic-core-2.27.2 pyjwt-2.10.1 python-slugify-8.0.4 pytz-2025.1 requests-2.32.3 rfc3161-client-0.1.2 rfc8785-0.1.4 rich-13.9.4 securesystemslib-1.2.0 sigstore-3.6.1 sigstore-protobuf-specs-0.3.2 sigstore-rekor-types-0.0.18 text-unidecode-1.3 tqdm-4.67.1 tuf-5.1.0 tzdata-2025.1 urllib3-2.3.0 webencodings-0.5.1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 24.0 -> 25.0.1\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "pip install kaggle kagglehub[pandas-datasets]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "!mv kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json  # Secure the file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "files.upload()  # Upload kaggle.json\n",
        "\n",
        "import os\n",
        "import json\n",
        "\n",
        "# Move the file to the correct location\n",
        "os.makedirs('/root/.kaggle', exist_ok=True)\n",
        "with open(\"kaggle.json\", \"r\") as f:\n",
        "    kaggle_creds = json.load(f)\n",
        "\n",
        "with open(\"/root/.kaggle/kaggle.json\", \"w\") as f:\n",
        "    json.dump(kaggle_creds, f)\n",
        "\n",
        "os.chmod(\"/root/.kaggle/kaggle.json\", 600)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import subprocess\n",
        "\n",
        "# List available datasets (optional)\n",
        "subprocess.run([\"kaggle\", \"datasets\", \"list\"])\n",
        "\n",
        "# Download ECG dataset\n",
        "subprocess.run([\"kaggle\", \"datasets\", \"download\", \"-d\", \"erhmrai/ecg-image-data\", \"--unzip\", \"-p\", \"/kaggle/input\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ['KAGGLE_CONFIG_DIR'] = \"/content\"\n",
        "!kaggle datasets download -d erhmrai/ecg-image-data -p /content --unzip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import shutil\n",
        "extracted_folder = \"/kaggle/input/ecg-image-data\"\n",
        "final_dataset_path = \"/kaggle/input/ecg_data\"\n",
        "if os.path.exists(extracted_folder):\n",
        "    shutil.move(extracted_folder, final_dataset_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import zipfile\n",
        "import kaggle\n",
        "\n",
        "# Set up Kaggle dataset information\n",
        "DATASET = \"erhmrai/ecg-image-data\"\n",
        "KAGGLE_INPUT_PATH = \"/kaggle/input\"\n",
        "KAGGLE_WORKING_PATH = \"/kaggle/working\"\n",
        "DATASET_ZIP_PATH = os.path.join(KAGGLE_INPUT_PATH, \"ecg-image-data.zip\")\n",
        "\n",
        "# Ensure input and working directories exist\n",
        "os.makedirs(KAGGLE_INPUT_PATH, exist_ok=True)\n",
        "os.makedirs(KAGGLE_WORKING_PATH, exist_ok=True)\n",
        "\n",
        "# Download the dataset using Kaggle API\n",
        "print(f\"Downloading dataset: {DATASET}...\")\n",
        "os.system(f\"kaggle datasets download -d {DATASET} -p {KAGGLE_INPUT_PATH} --unzip\")\n",
        "\n",
        "# Extract if zip file exists\n",
        "if os.path.exists(DATASET_ZIP_PATH):\n",
        "    print(\"Extracting dataset...\")\n",
        "    with zipfile.ZipFile(DATASET_ZIP_PATH, 'r') as zip_ref:\n",
        "        zip_ref.extractall(KAGGLE_INPUT_PATH)\n",
        "    os.remove(DATASET_ZIP_PATH)\n",
        "\n",
        "print(\"Dataset downloaded and extracted successfully!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from keras.layers import Input, Lambda, Dense, Flatten\n",
        "from keras.models import Model\n",
        "from keras.applications.vgg19 import VGG19\n",
        "from keras.applications.vgg16 import preprocess_input\n",
        "from keras.preprocessing import image\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential\n",
        "import numpy as np\n",
        "from glob import glob\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U6dm2u4wt2Ns"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The system cannot find the path specified.\n"
          ]
        },
        {
          "ename": "OSError",
          "evalue": "[WinError 1314] A required privilege is not held by the client: '/kaggle/input' -> '..\\\\input'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[1], line 24\u001b[0m\n\u001b[0;32m     21\u001b[0m os\u001b[38;5;241m.\u001b[39mmakedirs(KAGGLE_WORKING_PATH, \u001b[38;5;241m0o777\u001b[39m, exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 24\u001b[0m   \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msymlink\u001b[49m\u001b[43m(\u001b[49m\u001b[43mKAGGLE_INPUT_PATH\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m..\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43minput\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_is_directory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mFileExistsError\u001b[39;00m:\n\u001b[0;32m     26\u001b[0m   \u001b[38;5;28;01mpass\u001b[39;00m\n",
            "\u001b[1;31mOSError\u001b[0m: [WinError 1314] A required privilege is not held by the client: '/kaggle/input' -> '..\\\\input'"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from glob import glob\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Lambda, Dense, Flatten\n",
        "from tensorflow.keras.models import Model, Sequential\n",
        "from tensorflow.keras.applications.vgg19 import VGG19\n",
        "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# ✅ Fix: Ensure TensorFlow 2.x is used\n",
        "print(\"TensorFlow Version:\", tf.__version__)\n",
        "\n",
        "# Define dataset paths\n",
        "DATASET_PATH = \"/content/ECG_Image_data\"  # Change this to your dataset directory\n",
        "train_path = os.path.join(DATASET_PATH, \"train\")\n",
        "test_path = os.path.join(DATASET_PATH, \"test\")\n",
        "\n",
        "# Preprocessing and Data Augmentation\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1.0 / 255,  # Normalize images\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True\n",
        ")\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1.0 / 255)\n",
        "\n",
        "# Load Images\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_path,\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode=\"binary\"\n",
        ")\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    test_path,\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode=\"binary\"\n",
        ")\n",
        "\n",
        "# ✅ Load Pretrained VGG19 Model\n",
        "base_model = VGG19(input_shape=(224, 224, 3), weights=\"imagenet\", include_top=False)\n",
        "\n",
        "# Freeze VGG19 Layers\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Add Custom Layers\n",
        "x = Flatten()(base_model.output)\n",
        "x = Dense(128, activation=\"relu\")(x)\n",
        "x = Dense(1, activation=\"sigmoid\")(x)  # Binary Classification\n",
        "\n",
        "# Create Model\n",
        "model = Model(inputs=base_model.input, outputs=x)\n",
        "model.compile(optimizer=Adam(learning_rate=0.0001),\n",
        "              loss=\"binary_crossentropy\",\n",
        "              metrics=[\"accuracy\"])\n",
        "\n",
        "# Train Model\n",
        "history = model.fit(train_generator, validation_data=test_generator, epochs=5)\n",
        "\n",
        "# Save Model\n",
        "model.save(\"ecg_vgg19_model.h5\")\n",
        "\n",
        "print(\"✅ Model training complete! Saved as ecg_vgg19_model.h5\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9rM31d-5uBJ3"
      },
      "outputs": [],
      "source": [
        "IMAGE_SIZE = [224, 224]\n",
        "\n",
        "train_path = '../input/ecg-image-data/ECG_Image_data/train'\n",
        "valid_path = '../input/ecg-image-data/ECG_Image_data/test'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a6nr099duGxX"
      },
      "outputs": [],
      "source": [
        "vgg = VGG19(input_shape=IMAGE_SIZE + [3], weights='imagenet', include_top=False)\n",
        "\n",
        "for layer in vgg.layers:\n",
        "  layer.trainable = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E4YxykWYuNTe"
      },
      "outputs": [],
      "source": [
        "folders = glob('../input/ecg-image-data/ECG_Image_data/train/*')\n",
        "folders ////// check this"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h-X9ZlpHu_re"
      },
      "outputs": [],
      "source": [
        "x = Flatten()(vgg.output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UaUx_pIuyhXY"
      },
      "outputs": [],
      "source": [
        "prediction = Dense(len(folders), activation='softmax')(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_fnVrZLsyjzm"
      },
      "outputs": [],
      "source": [
        "model = Model(inputs=vgg.input, outputs=prediction)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "huBBP8jKyl4a"
      },
      "outputs": [],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RQ6UXQ-0yoc8"
      },
      "outputs": [],
      "source": [
        "model.compile(\n",
        "  loss='categorical_crossentropy',\n",
        "  optimizer='adam',\n",
        "  metrics=['accuracy']\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EJ5IM8CIyqSi"
      },
      "outputs": [],
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8fozaqA6ysNO"
      },
      "outputs": [],
      "source": [
        "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
        "                                   shear_range = 0.2,\n",
        "                                   zoom_range = 0.2,\n",
        "                                   horizontal_flip = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2dNsHWhDyttF"
      },
      "outputs": [],
      "source": [
        "test_datagen = ImageDataGenerator(rescale = 1./255)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8U5_k1djyvWO"
      },
      "outputs": [],
      "source": [
        "training_set = train_datagen.flow_from_directory('../input/ecg-image-data/ECG_Image_data/train',\n",
        "                                                 target_size = (224, 224),\n",
        "                                                 batch_size = 32,\n",
        "                                                 class_mode = 'categorical')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SQ466-I6yxEx"
      },
      "outputs": [],
      "source": [
        "test_set = test_datagen.flow_from_directory('../input/ecg-image-data/ECG_Image_data/test',\n",
        "                                            target_size = (224, 224),\n",
        "                                            batch_size = 32,\n",
        "                                            class_mode = 'categorical')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WL0kihZTyzL1"
      },
      "outputs": [],
      "source": [
        "r = model.fit_generator(\n",
        "  training_set,\n",
        "  validation_data=test_set,\n",
        "  epochs=3,\n",
        "  steps_per_epoch=len(training_set),\n",
        "  validation_steps=len(test_set)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E0ue3cVPy06s"
      },
      "outputs": [],
      "source": [
        "plt.plot(r.history['loss'], label='train loss')\n",
        "plt.plot(r.history['val_loss'], label='val loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "plt.savefig('LossVal_loss')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LxeAPwygy8t4"
      },
      "outputs": [],
      "source": [
        "plt.plot(r.history['accuracy'], label='train accuracy')\n",
        "plt.plot(r.history['val_accuracy'], label='val accuracy')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "plt.savefig('AccVal_accuracy')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gVhjBdtZzILN"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from keras.models import load_model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J-LK9lvTzLUr"
      },
      "outputs": [],
      "source": [
        "model.save('model_vgg19.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "53KJtiU0zMxm"
      },
      "outputs": [],
      "source": [
        "y_pred = model.predict(test_set)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sY7HU3ZhzONa"
      },
      "outputs": [],
      "source": [
        "y_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BC4u4JmkzPxf"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "y_pred = np.argmax(y_pred, axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d-oEiOPxzRVQ"
      },
      "outputs": [],
      "source": [
        "for i in range(len(y_pred)):\n",
        "  if y_pred[i]==1:\n",
        "    print(i)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cKBBUcSMzSzj"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.preprocessing import image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "msQFlazdzUSn"
      },
      "outputs": [],
      "source": [
        "model=load_model('model_vgg19.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SM72msqfzVw2"
      },
      "outputs": [],
      "source": [
        "img=image.load_img('../input/ecg-image-data/ECG_Image_data/test/F/F380.png',target_size=(224,224))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kiLSWfgQzXF7"
      },
      "outputs": [],
      "source": [
        "x=image.img_to_array(img)\n",
        "x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k6LHu-nwzaEa"
      },
      "outputs": [],
      "source": [
        "x.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7z00Y1c0zbVx"
      },
      "outputs": [],
      "source": [
        "x=x/255"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SffM4rTVzdIg"
      },
      "outputs": [],
      "source": [
        "x=np.expand_dims(x,axis=0)\n",
        "img_data=preprocess_input(x)\n",
        "img_data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VcJ-CAzDzekL"
      },
      "outputs": [],
      "source": [
        "model.predict(img_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cOw8tgzCzgKc"
      },
      "outputs": [],
      "source": [
        "a=np.argmax(model.predict(img_data), axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zahGcadtzhcS"
      },
      "outputs": [],
      "source": [
        "if(a==1):\n",
        "    print(\"Uninfected\")\n",
        "else:\n",
        "    print(\"Infected\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyPWVSQl4ZWL13i1W5y03GZ6",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
